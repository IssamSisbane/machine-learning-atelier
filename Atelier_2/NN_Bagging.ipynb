{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIG DATA - Réseaux de neurones et Bagging avec Python\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce travail a pour but de faire apprendre un classifier avec des reseau de neurones et du bagging et d'évaluer les performances de ce classifier sur des données de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports et bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=10000,suppress=True)\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import Perceptron \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Chargement de la base de données « Iris.txt »"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3  4\n",
       "0  5.1  3.5  1.4  0.2  1\n",
       "1  4.9  3.0  1.4  0.2  1\n",
       "2  4.7  3.2  1.3  0.2  1\n",
       "3  4.6  3.1  1.5  0.2  1\n",
       "4  5.0  3.6  1.4  0.2  1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_iris = pd.read_csv(\"iris.txt\", sep= \"\\t\", header=None)\n",
    "data_iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "# Transformation du DataFrame en un tableau numpy\n",
    "data_array = data_iris.values\n",
    "\n",
    "# Séparation des caractéristiques (X) de la variable à prédire (y)\n",
    "X = data_array[:, :-1]\n",
    "y = data_array[:, -1]\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Découpage de la base en Apprentissage/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble d'apprentissage : (100, 4) (100,)\n",
      "Taille de l'ensemble de test : (50, 4) (50,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=1)\n",
    "\n",
    "print(\"Taille de l'ensemble d'apprentissage :\", X_train.shape, y_train.shape)\n",
    "print(\"Taille de l'ensemble de test :\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Implémentation d’un Perceptron Multi-classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronMultiClass:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        unique_classes = np.unique(y)\n",
    "        self.class_to_index = {c: i for i, c in enumerate(unique_classes)}\n",
    "        self.index_to_class = {i: c for i, c in enumerate(unique_classes)}\n",
    "        \n",
    "        self.weights = np.zeros((X.shape[1], len(unique_classes)))\n",
    "        self.bias = np.zeros(len(unique_classes))\n",
    "        \n",
    "        for _ in range(self.n_iterations):\n",
    "            for i, x in enumerate(X):\n",
    "                target_class_index = self.class_to_index[y[i]]\n",
    "                \n",
    "                for class_index in range(len(self.weights[0])):\n",
    "                    target = 1 if class_index == target_class_index else 0\n",
    "                    prediction = self.predict_one(x, class_index)\n",
    "                    error = target - prediction\n",
    "                    \n",
    "                    self.weights[:, class_index] += self.learning_rate * error * x\n",
    "                    self.bias[class_index] += self.learning_rate * error\n",
    "\n",
    "    def predict_one(self, x, class_index):\n",
    "        return np.dot(x, self.weights[:, class_index]) + self.bias[class_index]\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            scores = [self.predict_one(x, class_index) for class_index in range(len(self.weights[0]))]\n",
    "            predicted_class_index = np.argmax(scores)\n",
    "            predicted_class = self.index_to_class[predicted_class_index]\n",
    "            predictions.append(predicted_class)\n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Évaluation des performances du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En premier lieu, il faut implémenter les fonctions qui font permettre d'evaluer les modèles.\n",
    "Cela comprend : \n",
    "* Matrice de confusion\n",
    "* Accuracy\n",
    "* Precision\n",
    "* Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_test, y_pred, num_classes):\n",
    "    matrix = [[0] * num_classes for _ in range(num_classes)]\n",
    "    for true, pred in zip(y_test, y_pred):\n",
    "        if true <= num_classes and pred <= num_classes: \n",
    "            matrix[int(true)-1][int(pred)-1] += 1 \n",
    "    return matrix\n",
    "\n",
    "\n",
    "def precision_score(y_test, y_pred, num_classes):\n",
    "    precision = []\n",
    "    for i in range(1, num_classes+1):\n",
    "        true_positive = sum(1 for true, pred in zip(y_test, y_pred) if true == i and pred == i)\n",
    "        false_positive = sum(1 for true, pred in zip(y_test, y_pred) if true != i and pred == i)\n",
    "        precision.append(true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0)\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall_score(y_test, y_pred, num_classes):\n",
    "    recall = []\n",
    "    for i in range(1, num_classes+1):\n",
    "        true_positive = sum(1 for true, pred in zip(y_test, y_pred) if true == i and pred == i)\n",
    "        false_negative = sum(1 for true, pred in zip(y_test, y_pred) if true == i and pred != i)\n",
    "        recall.append(true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0)\n",
    "    return recall\n",
    "\n",
    "\n",
    "def accuracy_score(y_test, y_pred):\n",
    "    correct = sum(1 for true, pred in zip(y_test, y_pred) if true == pred)\n",
    "    return correct / len(y_test)\n",
    "\n",
    "\n",
    "def evaluate_model(predictions, y_test, detailledMode=True):\n",
    "    y_pred = predictions\n",
    "\n",
    "    num_classes = len(set(y_test) | set(y_pred))\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred, num_classes)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, num_classes)\n",
    "    recall = recall_score(y_test, y_pred, num_classes)\n",
    "\n",
    "    if detailledMode:\n",
    "        print(\"Matrice de confusion :\")\n",
    "        for row in conf_matrix:\n",
    "            print(row)\n",
    "        print(\"Accuracy globale :\", accuracy)\n",
    "        print(\"Précision pour chaque classe :\", precision)\n",
    "        print(\"Rappel pour chaque classe :\", recall)\n",
    "    return accuracy, precision, recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On recherche les meilleurs parametres pour notre perceptron fait-maison.\n",
    "\n",
    "Nous allons tester plusieurs hyper-parametres : \n",
    "*  `learning rate` : 0.1, 0.01, 0.001, 0.0001\n",
    "* `iterations` : 1000, 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate : 0.1  - Iterations : 1000  - Accuracy : 0.34\n",
      "Learning rate : 0.1  - Iterations : 2000  - Accuracy : 0.34\n",
      "Learning rate : 0.01  - Iterations : 1000  - Accuracy : 0.64\n",
      "Learning rate : 0.01  - Iterations : 2000  - Accuracy : 0.64\n",
      "Learning rate : 0.001  - Iterations : 1000  - Accuracy : 0.74\n",
      "Learning rate : 0.001  - Iterations : 2000  - Accuracy : 0.76\n",
      "Learning rate : 0.0001  - Iterations : 1000  - Accuracy : 0.74\n",
      "Learning rate : 0.0001  - Iterations : 2000  - Accuracy : 0.74\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.1, 0.01, 0.001, 0.0001]\n",
    "iterations = [1000, 2000]\n",
    "best_accuracy = 0\n",
    "best_combo = {'learning_rate': 0, 'iteration': 0}\n",
    "results = []\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    for iteration in iterations:\n",
    "        perceptron = PerceptronMultiClass(learning_rate, iteration)\n",
    "        perceptron.fit(X_train, y_train)\n",
    "        predictions = perceptron.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        results.append({'learning_rate': learning_rate, 'iteration': iteration, 'accuracy': accuracy})\n",
    "        if (accuracy > best_accuracy):\n",
    "            best_accuracy = accuracy\n",
    "            best_combo['learning_rate'] = learning_rate\n",
    "            best_combo['iteration'] = iteration\n",
    "        print(\"Learning rate :\", learning_rate, \" - Iterations :\", iteration, \" - Accuracy :\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Finalement, nous observons que la combinaison de parametre qui maximise l'accuracy est un `learning rate` de 0.001 et un `nombre d'itérations` de 1000 (On s'aperçoit que cela ne change rien de changer le nombre d'itérations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron multi-classes fait maison avec les meilleurs paramètres\n",
    "perceptron = PerceptronMultiClass(best_combo['learning_rate'], best_combo['iteration'])\n",
    "perceptron.fit(X_train, y_train)\n",
    "predictions = perceptron.predict(X_test)\n",
    "\n",
    "print(\"Perceptron fait maison\\n\")\n",
    "evaluate_model(predictions, y_test)\n",
    "\n",
    "\n",
    "# Perceptron multi-classes de scikit-learn\n",
    "perceptronScikit = Perceptron()\n",
    "perceptronScikit.fit(X_train, y_train)\n",
    "predictionsScikit = perceptronScikit.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"\\n--------------------------------\")\n",
    "print(\"Perceptron de scikit-learn\\n\")\n",
    "evaluate_model(predictionsScikit, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On s'aperçoit que le Perceptron de scikit-learn a une bien meilleure accuracy que celui que nous avons implémenté nous même."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Implémentation d’un Percepron Multi-couches (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons essayer plusieurs paramètres pour le perceptron multi-couche afin de voir lesquels sont les meilleurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs paramètres trouvés: {'activation': 'tanh', 'learning_rate': 'constant', 'max_iter': 2000}\n",
      "Meilleur score d'accuracy : 0.9699940582293524\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(3,), random_state=1)\n",
    "\n",
    "params = {\n",
    "    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'max_iter': [1000, 2000]\n",
    "}\n",
    "# On utilise gridsearhc pour trouver les meilleurs paramètres\n",
    "grid_search = GridSearchCV(estimator=mlp, param_grid=params, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Affichage des meilleurs paramètres trouvés\n",
    "print(\"Meilleurs paramètres trouvés:\", grid_search.best_params_)\n",
    "print(\"Meilleur score d'accuracy :\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 - Évaluation des performances du modèle MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "[17, 0, 0]\n",
      "[0, 18, 1]\n",
      "[0, 0, 14]\n",
      "Accuracy globale : 0.98\n",
      "Précision pour chaque classe : [1.0, 1.0, 0.9333333333333333]\n",
      "Rappel pour chaque classe : [1.0, 0.9473684210526315, 1.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.98, [1.0, 1.0, 0.9333333333333333], [1.0, 0.9473684210526315, 1.0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utilisation des meilleurs paramètres trouvés\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(3,), activation=grid_search.best_params_['activation'], learning_rate=grid_search.best_params_['learning_rate'], max_iter=grid_search.best_params_['max_iter'], random_state=1)\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "predictionsMLP = mlp.predict(X_test)\n",
    "evaluate_model(predictionsMLP, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec le MLP et les meilleurs parametres, on obtient une très bonne accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "[17, 0, 0]\n",
      "[0, 18, 1]\n",
      "[0, 1, 13]\n",
      "Accuracy globale : 0.96\n",
      "Précision pour chaque classe : [1.0, 0.9473684210526315, 0.9285714285714286]\n",
      "Rappel pour chaque classe : [1.0, 0.9473684210526315, 0.9285714285714286]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.96,\n",
       " [1.0, 0.9473684210526315, 0.9285714285714286],\n",
       " [1.0, 0.9473684210526315, 0.9285714285714286])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "mlp.fit(X_train_normalized, y_train)\n",
    "\n",
    "predictions_mlp_normalized = mlp.predict(X_test_normalized)\n",
    "\n",
    "evaluate_model(predictions_mlp_normalized, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Application avec les différents datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all_dataset(datasets, results, neurons):\n",
    "    for dataset in datasets.keys():\n",
    "\n",
    "        data = datasets[dataset]\n",
    "        data_array = data.values\n",
    "        \n",
    "        X = data_array[:, :-1]\n",
    "        y = data_array[:, -1]\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=1)\n",
    "        \n",
    "        # Perceptron multi classes fait maison\n",
    "        perceptron = PerceptronMultiClass(learning_rate=0.001, n_iterations=1000)\n",
    "        perceptron.fit(X_train, y_train)\n",
    "        predictions = perceptron.predict(X_test)\n",
    "            \n",
    "        # MLP de scikit-learn    \n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(3,), random_state=1)\n",
    "        mlp.fit(X_train, y_train)\n",
    "        predictionsMLP = mlp.predict(X_test)\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_normalized = scaler.fit_transform(X_train)\n",
    "        X_test_normalized = scaler.transform(X_test)\n",
    "        \n",
    "        # MLP de scikit-learn normalisée\n",
    "        mlp.fit(X_train_normalized, y_train)\n",
    "        predictions_mlp_normalized = mlp.predict(X_test_normalized)\n",
    "        \n",
    "        # On évalue les modèles\n",
    "        accuracy1, precision1, rappel1 = evaluate_model(predictions, y_test, False)\n",
    "        accuracy2, precision2, rappel2 = evaluate_model(predictionsMLP, y_test, False)\n",
    "        accuracy3, precision3, rappel3 = evaluate_model(predictions_mlp_normalized, y_test, False)   \n",
    "        \n",
    "        # On ajoute les résultats au DataFrame\n",
    "        results[\"Dataset\"].append(dataset)\n",
    "        results[\"Model\"].append(\"Perceptron multi-classes fait maison\")\n",
    "        results[\"Accuracy\"].append(str(round(accuracy1*100, 2)) + \"%\")\n",
    "        results[\"Precision\"].append(precision1)\n",
    "        results[\"Rappel\"].append(rappel1)\n",
    "        \n",
    "        results[\"Dataset\"].append(dataset)\n",
    "        results[\"Model\"].append(\"Perceptron multi-couches de scikit-learn\")\n",
    "        results[\"Accuracy\"].append(str(round(accuracy2*100, 2)) + \"%\")\n",
    "        results[\"Precision\"].append(precision2)\n",
    "        results[\"Rappel\"].append(rappel2)\n",
    "        \n",
    "        results[\"Dataset\"].append(dataset)\n",
    "        results[\"Model\"].append(\"Perceptron multi-couches Scikit normalisé\")\n",
    "        results[\"Accuracy\"].append(str(round(accuracy3*100, 2)) + \"%\")\n",
    "        results[\"Precision\"].append(precision3)\n",
    "        results[\"Rappel\"].append(rappel3)\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Rappel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Glass</td>\n",
       "      <td>Perceptron multi-classes fait maison</td>\n",
       "      <td>38.89%</td>\n",
       "      <td>[0.3888888888888889, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Glass</td>\n",
       "      <td>Perceptron multi-couches de scikit-learn</td>\n",
       "      <td>30.56%</td>\n",
       "      <td>[0, 0.3055555555555556, 0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glass</td>\n",
       "      <td>Perceptron multi-couches Scikit normalisé</td>\n",
       "      <td>11.11%</td>\n",
       "      <td>[0, 0.3181818181818182, 0.0, 0, 0.020833333333...</td>\n",
       "      <td>[0.0, 0.3181818181818182, 0.0, 0, 0.3333333333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lsun</td>\n",
       "      <td>Perceptron multi-classes fait maison</td>\n",
       "      <td>96.27%</td>\n",
       "      <td>[0.9193548387096774, 1.0, 1.0]</td>\n",
       "      <td>[1.0, 0.8947368421052632, 0.9743589743589743]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lsun</td>\n",
       "      <td>Perceptron multi-couches de scikit-learn</td>\n",
       "      <td>29.1%</td>\n",
       "      <td>[0, 0.0, 0.319672131147541]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lsun</td>\n",
       "      <td>Perceptron multi-couches Scikit normalisé</td>\n",
       "      <td>61.19%</td>\n",
       "      <td>[0.8431372549019608, 0.0, 0.5492957746478874]</td>\n",
       "      <td>[0.7543859649122807, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wave</td>\n",
       "      <td>Perceptron multi-classes fait maison</td>\n",
       "      <td>79.42%</td>\n",
       "      <td>[0.9144254278728606, 0.7723342939481268, 0]</td>\n",
       "      <td>[0.6702508960573477, 0.9387040280210157, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wave</td>\n",
       "      <td>Perceptron multi-couches de scikit-learn</td>\n",
       "      <td>85.18%</td>\n",
       "      <td>[0.8846153846153846, 0.8088012139605463, 0]</td>\n",
       "      <td>[0.8243727598566308, 0.9334500875656743, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wave</td>\n",
       "      <td>Perceptron multi-couches Scikit normalisé</td>\n",
       "      <td>86.08%</td>\n",
       "      <td>[0.8841121495327103, 0.8632478632478633, 0]</td>\n",
       "      <td>[0.8476702508960573, 0.8844133099824869, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>Perceptron multi-classes fait maison</td>\n",
       "      <td>92.7%</td>\n",
       "      <td>[0.9107142857142857, 0.9692307692307692]</td>\n",
       "      <td>[0.9870967741935484, 0.8076923076923077]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>Perceptron multi-couches de scikit-learn</td>\n",
       "      <td>83.69%</td>\n",
       "      <td>[0.8342857142857143, 0.8448275862068966]</td>\n",
       "      <td>[0.9419354838709677, 0.6282051282051282]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>Perceptron multi-couches Scikit normalisé</td>\n",
       "      <td>95.71%</td>\n",
       "      <td>[0.967741935483871, 0.9358974358974359]</td>\n",
       "      <td>[0.967741935483871, 0.9358974358974359]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Dataset                                      Model Accuracy  \\\n",
       "0           Glass       Perceptron multi-classes fait maison   38.89%   \n",
       "1           Glass   Perceptron multi-couches de scikit-learn   30.56%   \n",
       "2           Glass  Perceptron multi-couches Scikit normalisé   11.11%   \n",
       "3            Lsun       Perceptron multi-classes fait maison   96.27%   \n",
       "4            Lsun   Perceptron multi-couches de scikit-learn    29.1%   \n",
       "5            Lsun  Perceptron multi-couches Scikit normalisé   61.19%   \n",
       "6            Wave       Perceptron multi-classes fait maison   79.42%   \n",
       "7            Wave   Perceptron multi-couches de scikit-learn   85.18%   \n",
       "8            Wave  Perceptron multi-couches Scikit normalisé   86.08%   \n",
       "9   Breast Cancer       Perceptron multi-classes fait maison    92.7%   \n",
       "10  Breast Cancer   Perceptron multi-couches de scikit-learn   83.69%   \n",
       "11  Breast Cancer  Perceptron multi-couches Scikit normalisé   95.71%   \n",
       "\n",
       "                                            Precision  \\\n",
       "0                 [0.3888888888888889, 0, 0, 0, 0, 0]   \n",
       "1                 [0, 0.3055555555555556, 0, 0, 0, 0]   \n",
       "2   [0, 0.3181818181818182, 0.0, 0, 0.020833333333...   \n",
       "3                      [0.9193548387096774, 1.0, 1.0]   \n",
       "4                         [0, 0.0, 0.319672131147541]   \n",
       "5       [0.8431372549019608, 0.0, 0.5492957746478874]   \n",
       "6         [0.9144254278728606, 0.7723342939481268, 0]   \n",
       "7         [0.8846153846153846, 0.8088012139605463, 0]   \n",
       "8         [0.8841121495327103, 0.8632478632478633, 0]   \n",
       "9            [0.9107142857142857, 0.9692307692307692]   \n",
       "10           [0.8342857142857143, 0.8448275862068966]   \n",
       "11            [0.967741935483871, 0.9358974358974359]   \n",
       "\n",
       "                                               Rappel  \n",
       "0                        [1.0, 0.0, 0.0, 0, 0.0, 0.0]  \n",
       "1                        [0.0, 1.0, 0.0, 0, 0.0, 0.0]  \n",
       "2   [0.0, 0.3181818181818182, 0.0, 0, 0.3333333333...  \n",
       "3       [1.0, 0.8947368421052632, 0.9743589743589743]  \n",
       "4                                     [0.0, 0.0, 1.0]  \n",
       "5                      [0.7543859649122807, 0.0, 1.0]  \n",
       "6         [0.6702508960573477, 0.9387040280210157, 0]  \n",
       "7         [0.8243727598566308, 0.9334500875656743, 0]  \n",
       "8         [0.8476702508960573, 0.8844133099824869, 0]  \n",
       "9            [0.9870967741935484, 0.8076923076923077]  \n",
       "10           [0.9419354838709677, 0.6282051282051282]  \n",
       "11            [0.967741935483871, 0.9358974358974359]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = {\n",
    "    \"Glass\": pd.read_csv(\"glass.txt\", header=None, sep=\"\\s+\"),\n",
    "    \"Lsun\": pd.read_csv(\"Lsun.txt\", header=None, sep=\"\\s+\"),\n",
    "    \"Wave\": pd.read_csv(\"Wave.txt\", header=None, sep=\"\\s+\"),\n",
    "    \"Breast Cancer\": pd.read_csv(\"breast-cancer-wisconsin.txt\", header=None, sep=\"\\s+\")\n",
    "}\n",
    "\n",
    "results = {\n",
    "    \"Dataset\": [],\n",
    "    \"Model\": [],\n",
    "    \"Accuracy\": [],\n",
    "    \"Precision\": [],\n",
    "    \"Rappel\": []\n",
    "}\n",
    "\n",
    "results_df = test_all_dataset(datasets, results, 3)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations et hypothèses\n",
    "\n",
    "Nous avons décidé de ne pas garder les hyper-parametres que nous avons trouvés précédemment car ces derniers ne sont optimisé que pour le dataset iris. Il aurait fallut refaire la demarche que nous avons fait précédemment de trouver les meilleurs paramètres pour chaque algo et pour chaque dataset.\n",
    "\n",
    "Nous evaluerons les datasets uniquement en utilisant l'accuracy. Nous n'avons pas assez d'information sur les datasets et le contexte d'usage de ces derniers pour pouvoir choisir si la mesure la plus adaptée est le recall ou la précision (sauf pour le dataset breast-cancer-wisconsin).\n",
    "\n",
    "Il a fallu modifier les fichiers contenant les datasets car les delimiters n'était pas constant à chaque ligne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Glass :**\n",
    "\n",
    "Nombre de données : `214`\n",
    "\n",
    "Nombre de classes : `6`\n",
    "\n",
    "Pour ce dataset, on s'aperçoit que le Perceptron multi-classes fait-maison renvoie la meilleure accuracy. On remarque que cette accuracy n'est vraiment pas très élevée > `40 %`. De plus, on observe qu'avec le perceptron multi-couches de scikit-learn, on a une accuracy encore inférieure `30.56%` et d'autant plus inférieur quand les données sont normalisés. \n",
    "\n",
    "Les valeurs d'accuracy que l'on obtient ne nous permettent pas de choisir un algo en particulier. En effet, comme nous avons moins de 50% d'accuracy ce n'est pas très pertinent d'utiliser ces algos.\n",
    "\n",
    "Une hypothèse pour expliquer cela serait les paramètres choisis qui ne sont pas adaptés. Plus particulièrement, on remarque que l'on a choisi 3 neurones pour le perceptron multi-couches. Cela peut sembler trop peu lorsque l'on regarde le dataset. En effet, les dataset propose 6 classes possibles (1,2,3,5,6,7). Ainsi, on pourrait peut-être améliorer l'accuracy en modifiant ce paramètre.\n",
    "On remarque aussi que le nombre de données est très faibls comparé aux autres datasets. Augmenter le nombre de données pourrait permettre d'améliorer l'accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lsun :**\n",
    "\n",
    "Nombre de données : `400`\n",
    "\n",
    "Nombre de classes : `6`\n",
    "\n",
    "Avec le perceptron multi-classes, on a une très bonne accuracy de `96.72%`. Le perceptron multi-couches sans normalisation renvoie une accuracy de `29.1%` et la normalisation augmente drastiquement l'accuracy à `61.19%`.\n",
    "\n",
    "On prendrait donc comme algo pour entrainter notre modèle, le perceptron multi-classes.\n",
    "\n",
    "Pareillement, il serait pertinent de trouver les hyper-paramètres qui maximisent l'accuracy pour avoir de meilleurs résultats avec le perceptron multi-couches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Glass</td>\n",
       "      <td>Perceptron multi-classes fait maison</td>\n",
       "      <td>38.89%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Glass</td>\n",
       "      <td>Perceptron multi-couches de scikit-learn</td>\n",
       "      <td>9.72%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glass</td>\n",
       "      <td>Perceptron multi-couches Scikit normalisé</td>\n",
       "      <td>50.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset                                      Model Accuracy\n",
       "0   Glass       Perceptron multi-classes fait maison   38.89%\n",
       "1   Glass   Perceptron multi-couches de scikit-learn    9.72%\n",
       "2   Glass  Perceptron multi-couches Scikit normalisé    50.0%"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = {\n",
    "    \"Glass\": pd.read_csv(\"glass.txt\", header=None, sep=\"\\s+\"),\n",
    "}\n",
    "\n",
    "results = {\n",
    "    \"Dataset\": [],\n",
    "    \"Model\": [],\n",
    "    \"Accuracy\": []\n",
    "    # \"Precision\": [],\n",
    "    # \"Rappel\": []\n",
    "}\n",
    "\n",
    "results_df = test_all_dataset(datasets, results, 7)\n",
    "results_df\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque donc ici qu'avec 7 couches, on a une bien meilleure accuracy soit `50%` avec un nombre de neurones de 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wave :**\n",
    "\n",
    "Nombre de données : `5000`\n",
    "\n",
    "Nombre de classes : `6`\n",
    "\n",
    "On a ici, un très bonne accuracy pour chacun des algos utilisés. On remarque que le perceptron multi-couches est meilleur que notre perceptron multi-classes et que la normalisation améliore encore légérement l'accuracy pour atteindre `86.08%`.\n",
    "\n",
    "On prendrait donc comme algo pour entrainer notre modèle, le perceptron multi-couches avec les données normalisées.\n",
    "\n",
    "Pareillement, il serait pertinent de trouver les hyper-paramètres qui maximisent l'accuracy pour avoir de meilleurs résultats avec le perceptron multi-couches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Breast Cancer :**\n",
    "\n",
    "Nombre de données : `699`\n",
    "\n",
    "Nombre de classes : `2`\n",
    "\n",
    "Les classifiers ont atteint les meilleurs scores avec ce dataset. En effet, on peut voir que le perceptron multi-classes renvoit une accuracy de `92.7%`. Le perceptron multi-couches renvoit une accuracy de `83.69%` et de `95.71%`.\n",
    "\n",
    "On prendrait donc comme algo pour entrainer notre modèle, le perceptron multi-couches avec les données normalisées.\n",
    "\n",
    "Pour ce jeu de données ont pourrait en plus utiliser une autre mesure pour évaluer le modèle soit le recall. En effet, ce dataset concerne des potentiels malades du cancer du sein au wisconsin. On pourrait imaginer que le contexte d'utilisation du modèle serait de determiner si une personne est atteinte au non du cancer du sein. On veut donc limiter le plus possible les faux negatifs soit le nombre de mauvais diagnostics (une personne n'est pas malade alors qu'elle l'est vraiment). Il faut ainsi maximiser le recall. \n",
    "On remarque que c'est le perceptron multi-couches avec les données normalisés. En effet, on est à : `93.5%`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion :**\n",
    "\n",
    "On remarque que en général, la normalisation des données améliore le client\n",
    "Les mauvaises performances du MLP peuvent s'expliquer par un paramètrages non approprié au problèmes et au dataset.\n",
    "\n",
    "Pour obtenir des meilleurs résultats, il aurait fallu tester plusieurs combinaisons de paramètres pour chaque dataset pour trouver des paramètres qui maximisent l'accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 - Bagging de réseaux de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de création d'échantillons bootstrap\n",
    "def create_bootstrap_samples(X_train, y_train, K):\n",
    "    bootstrap_samples = []\n",
    "    for _ in range(K):\n",
    "        X_bootstrap, y_bootstrap = resample(X_train, y_train)\n",
    "        bootstrap_samples.append((X_bootstrap, y_bootstrap))\n",
    "    return bootstrap_samples\n",
    "\n",
    "# Fonction qui permet de rééchantillonner les données\n",
    "def resample(X, y):\n",
    "    n_samples = X.shape[0]\n",
    "    indices = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "    return X[indices], y[indices]\n",
    "\n",
    "# Fonction qui permet d'entraîner un classifieur MLP\n",
    "def train_mlp_classifier(X_train, y_train):\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(100,), random_state=1)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    return mlp\n",
    "\n",
    "# Fonction qui permet d'agréger les prédictions des classifieurs\n",
    "def aggregate_models(classifiers):\n",
    "    def predict_ensemble(X):\n",
    "        predictions = np.array([clf.predict(X) for clf in classifiers])\n",
    "        aggregated_predictions = np.mean(predictions, axis=0)\n",
    "        return np.round(aggregated_predictions).astype(int)\n",
    "    return predict_ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------\n",
      "Dataset : Glass\n",
      "Matrice de confusion :\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "[28, 22, 7, 0, 3, 2]\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "Accuracy globale : 0.3055555555555556\n",
      "Précision pour chaque classe : [0.0, 1.0, 0.0, 0, 0.0, 0.0]\n",
      "Rappel pour chaque classe : [0, 0.3055555555555556, 0, 0, 0, 0]\n",
      "\n",
      "------------------\n",
      "Dataset : Lsun\n",
      "Matrice de confusion :\n",
      "[57, 0, 0]\n",
      "[0, 38, 0]\n",
      "[0, 0, 39]\n",
      "Accuracy globale : 1.0\n",
      "Précision pour chaque classe : [1.0, 1.0, 1.0]\n",
      "Rappel pour chaque classe : [1.0, 1.0, 1.0]\n",
      "\n",
      "------------------\n",
      "Dataset : Wave\n",
      "Matrice de confusion :\n",
      "[449, 39, 62]\n",
      "[42, 490, 31]\n",
      "[67, 42, 445]\n",
      "Accuracy globale : 0.8302339532093581\n",
      "Précision pour chaque classe : [0.8046594982078853, 0.8581436077057794, 0]\n",
      "Rappel pour chaque classe : [0.8163636363636364, 0.8703374777975134, 0]\n",
      "\n",
      "------------------\n",
      "Dataset : Breast Cancer\n",
      "Matrice de confusion :\n",
      "[152, 7]\n",
      "[3, 71]\n",
      "Accuracy globale : 0.9570815450643777\n",
      "Précision pour chaque classe : [0.9806451612903225, 0.9102564102564102]\n",
      "Rappel pour chaque classe : [0.9559748427672956, 0.9594594594594594]\n"
     ]
    }
   ],
   "source": [
    "K = int(input(\"Entrez le nombre d'échantillons bootstrap (K) : \"))\n",
    "for dataset in datasets.keys():\n",
    "    # On teste sur le dataset Iris\n",
    "    data = datasets[dataset]\n",
    "\n",
    "    data_array = data.values\n",
    "    X = data_array[:, :-1]\n",
    "    y = data_array[:, -1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=1)\n",
    "    \n",
    "    # Création des échantillons\n",
    "    bootstrap_samples = create_bootstrap_samples(X_train, y_train, K)\n",
    "    # On créer les classifieurs pour chaque échantillon\n",
    "    classifiers = [train_mlp_classifier(X_bootstrap, y_bootstrap) for X_bootstrap, y_bootstrap in bootstrap_samples]\n",
    "    # On agrège les prédictions des classifieurs\n",
    "    ensemble_classifier = aggregate_models(classifiers)\n",
    "    # On fait les prédictions sur l'ensemble de test\n",
    "    predictions_ensemble = ensemble_classifier(X_test)\n",
    "\n",
    "    print(\"\\n------------------\")\n",
    "    print(\"Dataset :\", dataset)\n",
    "    evaluate_model(y_test, predictions_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En testant avec K = 5, on remarque que les resultats sont bien meilleurs pour le dataset Glass et Lsun avec le perceptron multi-couches.\n",
    "Pour le dataset Wave, les résultats sont similaires avec ou sans bagging.\n",
    "Pour le dataset Breast Cancer, les résultats sont meilleurs pour le perceptron multi-couches normalisé sans le bagging."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
